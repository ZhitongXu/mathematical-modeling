{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from IPython.display import display\n",
    "from tqdm import tqdm\n",
    "from collections import Counter\n",
    "import ast\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.mlab as mlab\n",
    "import seaborn as sb\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import nltk\n",
    "from nltk import ngrams\n",
    "from itertools import chain\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.tag import pos_tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat = pd.read_csv('hairdryer_cleaned.csv', header=0)\n",
    "# dat = pd.read_csv('microwave_cleaned.csv', header=0)\n",
    "# dat = pd.read_csv('pacifier_cleaned.csv', header=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction import text\n",
    "my_stopwords = text.ENGLISH_STOP_WORDS.union(['hair','dryer','dryers','hairdryer','dry',\n",
    "                                              'br','product','use','using','used','amazon','did','does','do','just'])\n",
    "# ['microwave','oven','product','one','use','used','just','buy','bought','does','did','do'])\n",
    "# ['baby','pacifier','pacifiers','product','did','does','do','just','buy','bought'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# popular single adjective word people used for different score\n",
    "def get_token_adj(score, benchmark):\n",
    "    df = dat[dat['star_rating'] == score]['review_body']\n",
    "    \n",
    "    count = len(df)\n",
    "    total_text = ' '.join(df)\n",
    "    total_text = total_text.lower()\n",
    "    stop = set(my_stopwords)\n",
    "    total_text = nltk.word_tokenize(total_text)\n",
    "    total_text = [word for word in total_text if word not in stop and len(word) >= 3]\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    total_text = [lemmatizer.lemmatize(w,'a') for w in total_text]\n",
    "    # get adjective only\n",
    "    total_text = [word for word, form in nltk.pos_tag(total_text) if form == 'JJ']\n",
    "    \n",
    "    text = nltk.Text(total_text)\n",
    "    fdist = nltk.FreqDist(text)\n",
    "    \n",
    "    # return only phrase occurs more than benchmark of his reviews\n",
    "    return sorted([(w,fdist[w],str(round(fdist[w]/count*100,2))+'%') for w in set(text) if fdist[w] >= count*benchmark], key=lambda x: -x[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score 1 reviews most popular adjectives word:\n",
      "   Count Occur % Phrase\n",
      "0  185.0  18.56%    hot\n",
      "1  171.0  17.15%   good\n",
      "2  100.0  10.03%    bad\n",
      "3   97.0   9.73%   high\n",
      "4   96.0   9.63%  great\n",
      "5   92.0   9.23%    low\n",
      "6   92.0   9.23%    new\n",
      "7   67.0   6.72%   long\n",
      "score 2 reviews most popular adjectives word:\n",
      "    Count Occur %       Phrase\n",
      "0   159.0   25.9%         good\n",
      "1   155.0  25.24%          hot\n",
      "2    88.0  14.33%         high\n",
      "3    85.0  13.84%        great\n",
      "4    66.0  10.75%          low\n",
      "5    63.0  10.26%          old\n",
      "6    60.0   9.77%          new\n",
      "7    54.0   8.79%         long\n",
      "8    50.0   8.14%        heavy\n",
      "9    50.0   8.14%         fine\n",
      "10   48.0   7.82%        small\n",
      "11   43.0    7.0%       little\n",
      "12   41.0   6.68%        short\n",
      "13   40.0   6.51%  retractable\n",
      "14   40.0   6.51%     powerful\n",
      "score 3 reviews most popular adjectives word:\n",
      "    Count Occur %    Phrase\n",
      "0   291.0  30.28%      good\n",
      "1   172.0   17.9%       hot\n",
      "2   147.0   15.3%      high\n",
      "3   146.0  15.19%     great\n",
      "4   135.0  14.05%     heavy\n",
      "5   116.0  12.07%       low\n",
      "6   104.0  10.82%    little\n",
      "7    96.0   9.99%  powerful\n",
      "8    90.0   9.37%       old\n",
      "9    87.0   9.05%      long\n",
      "10   83.0   8.64%      fine\n",
      "11   81.0   8.43%      nice\n",
      "12   79.0   8.22%     quiet\n",
      "13   75.0    7.8%     small\n",
      "14   68.0   7.08%       big\n",
      "15   66.0   6.87%     short\n",
      "score 4 reviews most popular adjectives word:\n",
      "    Count Occur %    Phrase\n",
      "0   713.0  35.12%      good\n",
      "1   602.0  29.66%     great\n",
      "2   316.0  15.57%    little\n",
      "3   289.0  14.24%       hot\n",
      "4   256.0  12.61%      high\n",
      "5   247.0  12.17%      easy\n",
      "6   232.0  11.43%     heavy\n",
      "7   206.0  10.15%       low\n",
      "8   199.0    9.8%       old\n",
      "9   191.0   9.41%      nice\n",
      "10  185.0   9.11%     small\n",
      "11  173.0   8.52%  powerful\n",
      "12  144.0   7.09%     light\n",
      "13  142.0    7.0%     quiet\n",
      "14  142.0    7.0%      long\n",
      "score 5 reviews most popular adjectives word:\n",
      "     Count Occur %    Phrase\n",
      "0   2238.0  34.38%     great\n",
      "1   1478.0  22.71%      good\n",
      "2    682.0  10.48%      easy\n",
      "3    680.0  10.45%       old\n",
      "4    608.0   9.34%       hot\n",
      "5    595.0   9.14%  powerful\n",
      "6    545.0   8.37%    little\n",
      "7    525.0   8.07%      nice\n",
      "8    483.0   7.42%     small\n",
      "9    480.0   7.37%      high\n",
      "10   479.0   7.36%     quiet\n",
      "11   424.0   6.51%     happy\n"
     ]
    }
   ],
   "source": [
    "index = ['Phrase', 'Count', 'Occur %']\n",
    "\n",
    "for j in range(1,6):\n",
    "    test = pd.DataFrame()\n",
    "    d = get_token_adj(j, 0.065)\n",
    "    print('score {} reviews most popular adjectives word:'.format(j))\n",
    "    for i in d:\n",
    "        test = test.append(pd.Series(i, index = index), ignore_index = True)\n",
    "    test = test.sort_values('Count', ascending=False)\n",
    "    print(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# frequent phrases\n",
    "def get_token_ngram(score, benchmark):\n",
    "    df = dat[dat['star_rating'] == score]['review_body']\n",
    "        \n",
    "    count = len(df)\n",
    "    total_text = ' '.join(df)\n",
    "    total_text = total_text.lower()\n",
    "    stop = set(my_stopwords)\n",
    "    total_text = nltk.word_tokenize(total_text)\n",
    "    total_text = [word for word in total_text if word not in stop and len(word) >= 3]\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    total_text = [lemmatizer.lemmatize(w,'v') for w in total_text]\n",
    "    bigrams = ngrams(total_text,2)\n",
    "    trigrams = ngrams(total_text, 3)\n",
    "\n",
    "\n",
    "    # look at 2-gram and 3-gram together\n",
    "    combine = chain(bigrams, trigrams)\n",
    "    text = nltk.Text(combine)\n",
    "    fdist = nltk.FreqDist(text)\n",
    "    \n",
    "    # return only phrase occurs more than benchmark of his reviews\n",
    "    return sorted([(w,fdist[w],str(round(fdist[w]/count*100,2))+'%') for w in set(text) if fdist[w] >= count*benchmark], key=lambda x: -x[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score 1 reviews most popular 2-gram / 3-gram:\n",
      "    Count Occur %               Phrase\n",
      "0   102.0  10.23%         (stop, work)\n",
      "1    67.0   6.72%       (waste, money)\n",
      "2    45.0   4.51%  (retractable, cord)\n",
      "3    36.0   3.61%           (n't, buy)\n",
      "4    30.0   3.01%       (work, months)\n",
      "5    30.0   3.01%        (work, great)\n",
      "6    30.0   3.01%       (read, review)\n",
      "7    29.0   2.91%        (months, ago)\n",
      "8    27.0   2.71%         (n't, waste)\n",
      "9    26.0   2.61%          (n't, work)\n",
      "10   26.0   2.61%         (quit, work)\n",
      "11   25.0   2.51%        (wall, mount)\n",
      "12   23.0   2.31%  (n't, waste, money)\n",
      "13   23.0   2.31%           (get, hot)\n",
      "14   22.0   2.21%           (hot, air)\n",
      "15   20.0   2.01%       (last, months)\n",
      "score 2 reviews most popular 2-gram / 3-gram:\n",
      "    Count Occur %               Phrase\n",
      "0    47.0   7.65%         (stop, work)\n",
      "1    39.0   6.35%  (retractable, cord)\n",
      "2    33.0   5.37%         (work, fine)\n",
      "3    22.0   3.58%        (wall, mount)\n",
      "4    20.0   3.26%           (hot, air)\n",
      "5    19.0   3.09%           (n't, hot)\n",
      "6    17.0   2.77%        (last, years)\n",
      "7    17.0   2.77%        (work, great)\n",
      "9    15.0   2.44%           (get, hot)\n",
      "10   15.0   2.44%          (air, flow)\n",
      "8    15.0   2.44%          (n't, work)\n",
      "11   14.0   2.28%        (n't, really)\n",
      "12   14.0   2.28%     (n't, recommend)\n",
      "13   14.0   2.28%         (feel, like)\n",
      "14   14.0   2.28%          (n't, know)\n",
      "15   13.0   2.12%       (really, like)\n",
      "16   13.0   2.12%        (months, ago)\n",
      "17   13.0   2.12%          (high, set)\n",
      "18   13.0   2.12%     (heat, settings)\n",
      "19   13.0   2.12%           (low, set)\n",
      "20   13.0   2.12%       (read, review)\n",
      "score 3 reviews most popular 2-gram / 3-gram:\n",
      "    Count Occur %               Phrase\n",
      "0    54.0   5.62%  (retractable, cord)\n",
      "1    41.0   4.27%         (work, fine)\n",
      "2    31.0   3.23%     (heat, settings)\n",
      "3    30.0   3.12%         (stop, work)\n",
      "4    28.0   2.91%        (cool, shoot)\n",
      "5    25.0    2.6%        (work, great)\n",
      "6    24.0    2.5%           (get, job)\n",
      "7    22.0   2.29%        (high, speed)\n",
      "8    21.0   2.19%          (n't, work)\n",
      "9    21.0   2.19%           (n't, hot)\n",
      "10   21.0   2.19%         (low, speed)\n",
      "11   21.0   2.19%      (shoot, button)\n",
      "12   21.0   2.19%       (take, longer)\n",
      "13   21.0   2.19%          (air, flow)\n",
      "14   20.0   2.08%          (heat, set)\n",
      "score 4 reviews most popular 2-gram / 3-gram:\n",
      "    Count Occur %               Phrase\n",
      "0   141.0   6.95%        (work, great)\n",
      "1    93.0   4.58%  (retractable, cord)\n",
      "2    65.0    3.2%     (heat, settings)\n",
      "3    59.0   2.91%       (dry, quickly)\n",
      "4    59.0   2.91%       (really, like)\n",
      "5    57.0   2.81%         (work, fine)\n",
      "6    54.0   2.66%       (night, light)\n",
      "7    49.0   2.41%      (light, weight)\n",
      "8    47.0   2.32%        (wall, mount)\n",
      "9    46.0   2.27%         (give, star)\n",
      "10   45.0   2.22%          (dry, fast)\n",
      "11   43.0   2.12%        (cool, shoot)\n",
      "score 5 reviews most popular 2-gram / 3-gram:\n",
      "   Count Occur %               Phrase\n",
      "0  484.0   7.44%        (work, great)\n",
      "1  291.0   4.47%  (highly, recommend)\n",
      "2  250.0   3.84%       (dry, quickly)\n",
      "3  209.0   3.21%  (retractable, cord)\n",
      "4  192.0   2.95%      (light, weight)\n",
      "5  170.0   2.61%          (dry, time)\n",
      "6  166.0   2.55%     (heat, settings)\n",
      "7  163.0    2.5%         (love, love)\n",
      "8  161.0   2.47%          (dry, fast)\n",
      "9  147.0   2.26%       (great, price)\n"
     ]
    }
   ],
   "source": [
    "index = ['Phrase', 'Count', 'Occur %']\n",
    "\n",
    "for j in range(1,6):\n",
    "    test = pd.DataFrame()\n",
    "    d = get_token_ngram(j, 0.02)\n",
    "    print('score {} reviews most popular 2-gram / 3-gram:'.format(j))\n",
    "    for i in d:\n",
    "        test = test.append(pd.Series(i, index = index), ignore_index = True)\n",
    "    test = test.sort_values('Count', ascending=False)\n",
    "    print(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
